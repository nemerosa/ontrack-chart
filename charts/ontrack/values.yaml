# Default values for ontrack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: nemerosa/ontrack
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  # tag: ""

imagePullSecrets: [ ]
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: { }
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: { }

podSecurityContext: { }
# fsGroup: 2000

securityContext: { }
  # capabilities:
  #   drop:
  #   - ALL
# readOnlyRootFilesystem: true
# runAsNonRoot: true
# runAsUser: 1000

service:
  type: ClusterIP
  port: 8080
  annotations: { }

management:
  service:
    port: 8800
    # Set to true to have the management port exposed by another Service
    # By default, using the same service and two different named ports
    specific: false
    # Annotations for the management service
    # Only used when specific == true
    annotations: { }
    # Service type for the management
    # Only used when specific == true
    type: ClusterIP

ingress:
  enabled: false
  annotations: {}
  host: "ontrack.local"
  tls:
    enabled: true

# nodeSelector: {}

# tolerations: []

# affinity: {}

# Ontrack configuration
ontrack:
  # Ontrack root URL - must point to the UI service
  url: "http://localhost:3000"
  # Comma-separated list of active Spring profiles
  profiles: prod
  # Application configuration file as a YAML content
  application_yaml: ""
  ## Next UI setup (experimental)
  ui:
    # Number of replicas
    replicas: 1
    # Image to use
    image: nemerosa/ontrack-ui
    # Service
    service:
      # Port to expose
      port: 3000
    # Next UI resources
    resources:
      limits:
        cpu: 800m
        memory: 1Gi
      requests:
        cpu: 800m
        memory: 1Gi
  ## Adjust these values to your needs, but make sure that the memory limit is never under 4 GB
  resources:
    limits:
      cpu: 800m
      memory: 2Gi
    requests:
      cpu: 800m
      memory: 1Gi
  # Persistence configuration
  persistence:
    # By default, not using a persistent storage
    enabled: false
    # Set annotations on pvc
    annotations: { }
    # PVC access mode
    accessMode: ReadWriteOnce
    # PVC initial size
    size: 5Gi
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    storageClass:
  # Ontrack configuration properties
  config:
    # Using the database to store the key by default
    key_store: jdbc
    # If key_store == "secret"
    secret_key_store:
      # Name of the secret
      secret_name: "ontrack-key-store"
      # Directory to use inside the container
      directory: "/var/ontrack/key_store"
    # License management
    license:
      # Type of license: none, stripe, fixed
      type: none
      # For Fixed based configuration
      fixed:
        # Type of license, display name, description, etc.
        name:
        # Name of the assignee
        assignee:
        # Is the license active?
        active: false
        # End of validity for this license (null for unlimited)
        validUntil:
        # Maximum number of projects which can be created (0 for unlimited)
        maxProjects: 0
      # For Stripe based configuration
      stripe:
        # Name of the secret which contains the Stripe information
        secret: ontrack-license-stripe
        # Name of the secret key which contains the API key
        token_key_name: token
        # Name of the secret key which contains ID of the Stripe subscription
        subscription_key_name: subscription
      # For embedded license key
      embedded:
        # Provided license key
        key: ""
  # Management configuration
  management:
    metrics:
      # Tags to add to all exposed metrics
      tags:
        application: "ontrack"
        application_instance: "ontrack"

  # Arbitrary environment variables
  env: [ ]

  # Arbitrary secrets & config map sources
  extraConfig:
    secrets: [ ]
    # secrets:
    #   - secret-name
    configmaps: [ ]
    # configmaps:
    #   - config-map-name

  # CasC configuration
  casc:
    # Is Casc enabled?
    enabled: false
    # Config map containing all Casc files
    map: ""
    # Secret map containing all secret Casc files
    secret: ""
    # Path where to mount the Casc files
    directory: "/var/ontrack/casc"
    # Mapping of secrets
    secrets:
      # Secret mapping mode
      mapping: env
      # Directory where to map the secrets (for mapping = env)
      directory: "/var/ontrack/casc/mapping"
      # List of secret names to mount
      names: []
    # Auto reload configuration
    reloading:
      # Auto reload activation
      enabled: false
      # Auto reload cron schedule
      # Leave empty to be a manual job only
      cron: ""
    # Uploading the Casc
    upload:
      # Enabled
      enabled: false
    # Casc from values
    mapValues:
      # Enabling the creating & mapping of a config map holding Casc values
      # Casc values are expected to be under the root `casc` object, for example
      # casc:
      #   ontrack:
      #     # ...
      # Name of the entry to hold the values
      mapEntryName: "casc.yaml"

# Authentication
auth:
  keycloak:
    enabled: true
    image: quay.io/keycloak/keycloak
    tag: 26.1.4
    bootstrap:
      username: admin
      password: admin
    external:
      enabled: false
      url: https://keycloak
    service:
      port: 8008
      path: keycloak
    resources: {}
    realm: ontrack
    settings:
      enabled: true
      registrationAllowed: true
      resetPasswordAllowed: true
      admin:
        username: "admin"
        email: "admin@ontrack.local"
        firstName: "Admin"
        lastName: "User"
        password: "admin"
    secret:
      enabled: false
      name: ontrack-keycloak
    client:
      id: ontrack-client
      secret: ontrack-client-secret
  secret: xxx

# Local database for testing purpose
postgresql:
  local: true
  # Authentication parameters
  auth:
    # Name of the database to create
    database: ontrack
    # Credentials to be used
    username: ontrack
    password: ontrack
  # Configuration for the container database
#  primary:
#    pgHbaConfiguration: |-
#      host all all 0.0.0.0/0 trust
  # For external database
  postgresqlUrl: ""
  # For external database, using environment variables
  postgresFromEnv: false

# Local RabbitMQ for message processing
rabbitmq:
  auth:
    username: ontrack
    password: ontrack
    erlangCookie: ontrack

# Local Elasticsearch engine for testing purpose
elasticsearch:
  enabled: true
  maxUnavailable: 0 # Even in K8S 1.25, the Pod Disruption budget is generated for policy/v1beta instead of policy/v1
  replicas: 1
  minimumMasterNodes: 1
  antiAffinity: soft
  masterService: ontrack-search
  esJavaOpts: -Xmx512m -Xms512m -XX:-HeapDumpOnOutOfMemoryError
  clusterHealthCheckParams: 'wait_for_status=yellow&timeout=1s'
  esConfig:
    elasticsearch.yml: |
      discovery.zen.minimum_master_nodes: 1
      bootstrap.system_call_filter: "false"
      node.max_local_storage_nodes: 8
      cluster.routing.allocation.disk.threshold_enabled: "false"
      action.auto_create_index: ".*"
      # Disabling security warnings
      xpack.security.enabled: "false"
  resources:
    requests:
      cpu: 300m
      memory: 1024M
    limits:
      memory: 1024M
  volumeClaimTemplate:
    accessModes: [ ReadWriteOnce ]
    resources:
      requests:
        storage: 5Gi

# In case you want to specify different resources for emptyDir than {}
emptyDir: { }
  # Example of resouces that might be used:
  # medium: Memory
# sizeLimit: 16Mi

## Array of extra containers to run alongside the Ontrack container
##
## Example:
## - name: myapp-container
##   image: busybox
##   command: ['sh', '-c', 'echo Hello && sleep 3600']
##
extraContainers: [ ]
